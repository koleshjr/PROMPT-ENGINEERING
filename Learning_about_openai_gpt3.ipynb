{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTh5amW3e/ZWnOJTKVyvf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koleshjr/PROMPT-ENGINEERING/blob/main/Learning_about_openai_gpt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROMPT ENGINEERING USING GPT-3\n"
      ],
      "metadata": {
        "id": "NgffXJAWlFW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proof of concept\n",
        "* built gradually over time\n",
        "* for a starting example: {'category','key','value'}\n",
        "\n",
        "###### Steps\n",
        "* Extract facts from Natural Language and adding them to a database\n",
        "* search the database using key words\n",
        "\n",
        "###### Prompt Engineering\n",
        "* Prompts inputs both instructions and content to the model\n",
        "* It requires an appropriate language processing architecture to deal with prompt composition and later model output interpretation\n",
        "* It also requires gradual refinement of the prompts carefully examining the results to iteratively improve them\n",
        "\n",
        "###### General architecture\n",
        "* Pre-processing -> prompt -> GPT-3 -> row_output -> postprocessing -> suitable data structure -> application usage\n",
        "\n",
        "###### Iterative prompt development\n",
        "* Write a prompt, test it with the available data (or just a couple manual inputs) , examine the mistakes, fix the prompt to account for those mistakes and repeat\n",
        "\n",
        "* If you don't get some interesting results in your first iterations, perhaps you should consider using another technique rather than GPT-3"
      ],
      "metadata": {
        "id": "e8mvT28flJbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notice the Iteration Life cycle in the below examples for prompt engineering\n",
        "\n",
        "##### Example 3\n",
        "* Extraction prompt 3, given user input x\n",
        "\n",
        "* Extract pieces of personal information, like phone numbers, email \n",
        "addresses, names, trivia, reminders, etc., as tuples with the following \n",
        "format: (Category, Key, Value)\n",
        "\n",
        "* Example input: \"Mom's phone number is 555-555-5555\"\n",
        "Example output: (\"Family\", \"mom's phone number\", \"555-555-5555\")\n",
        "\n",
        "\n",
        "\n",
        "###### Example 5: \n",
        "* Extraction prompt 4, given user input x and valid categories\n",
        "\n",
        "* Extract pieces of personal information, like phone numbers, email \n",
        "addresses, names, trivia, reminders, etc., as tuples with the following \n",
        "format: (Category, Key, Value)\n",
        "Assume everything mentioned refers to the same thing. Constraints:\n",
        "  - Allowed Categories: {', '.join(categories)}\n",
        "\n",
        "\n",
        "* Example input: \"Mom's phone number is 555-555-5555\"\n",
        "Example output: (\"Family\", \"mom's phone number\", \"555-555-5555\")\n",
        "\n",
        "* Example input: \"Need to do: lab work, ultrasound, buy aspirin\"\n",
        "Example output: \n",
        "(\"Health\", \"to do\", \"lab work\")\n",
        "(\"Health\", \"to do\", \"ultrasound\")\n",
        "(\"Health\", \"buy\", \"aspirin\") \n",
        "\n",
        "#### Example 6:\n",
        "* Extraction prompt 5, given user input x and valid categories\n",
        "\n",
        "* Extract pieces of personal information, like phone numbers, email \n",
        "addresses, names, trivia, reminders, etc., as tuples with the following \n",
        "format: (Category, Type, People, Key, Value)\n",
        "Assume everything mentioned refers to the same thing. Constraints:\n",
        "  - Allowed Categories: {', '.join(categories)}\n",
        "  - Allowed Types: \"List\", \"Email\", \"Phone\", \"Address\", \"Document\", \n",
        "    \"Pendency\", \"Price\", \"Reminder\", \"Note\", \"Doubt\", \"Wish\", \"Other\"\n",
        "  - People contain the name or description of the people or organizations \n",
        "    concerned, or is empty if no person or organization is mentioned.\n",
        "  \n",
        "* Example input: \"Mom's phone number is 555-555-5555\"\n",
        "Example output: (\"Family\", \"Phone\", \"mom\", \"mom's number\", \"555-555-5555\")\n",
        "\n",
        "* Example input: \"email of the building administration = adm@example.com\"\n",
        "Example output: (\"Work\", \"Email\", \"building administration\", \n",
        "                 \"email\", \"adm@example.com\")\n",
        "\n",
        "* Example input: \"Need to do: lab work, ultrasound, buy aspirin\"\n",
        "Example output: \n",
        "(\"Health\", \"List\", \"\", \"to do\", \"lab work\")\n",
        "(\"Health\", \"List\", \"\", \"to do\", \"ultrasound\")\n",
        "(\"Shopping\", \"List\", \"\", \"aspirin\", \"buy\")  \n",
        "\n",
        "\n",
        "###### NB: We can get more accurate results by changing the temperature parameter by increeasing it from 0.5 to 0.1\n"
      ],
      "metadata": {
        "id": "tEZwJYx7vf1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notice the iteration life cycle for search below\n",
        "* Procedure involves looking for any of the key words that the user queried, if the fact exists in a database it is returned\n",
        "\n",
        "* GPT3 - Extracts the main terms from a query\n",
        "* Augment the main terms with related ones\n",
        "\n",
        "#### Example 1: Query terms extraction prompt, given user query\n",
        "\n",
        "* Extract the main entities (one per line, without bullets) in the following \n",
        "sentence: \"{query}\"\n",
        "\n",
        "* input : what is the cost of a flu shot?\n",
        "* Output: flu shot and cost\n",
        "* Input : What is the cost of a flu shot?\n",
        "* Output : Pediatrician and Questions\n",
        "\n",
        "#### Example2:Data augmentation prompt, given a term\n",
        "\n",
        "* List some synonyms for the following term: \"{term}\"\n",
        "Synonyms (one synonym per line):\n",
        "\n",
        "* E.g flu shot: Vaccination, Injection, Immunization, Jab\n",
        "* E.g Pediatrician: Child Doctor, Pediatrician, Infant Specialist, Kids Physician\n",
        "\n",
        "##### Work Flow\n",
        "* Get a user input, extract its main terms, augment them, and then search a dataframe for them. \n",
        "\n"
      ],
      "metadata": {
        "id": "AmYwCbnD0A8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application Development\n",
        "* The Engine: A python Library that encapsulates the main functions required to make the application work. Classes and Methods here are to abstract the calls to GPT-3 so that users of the library don't need to be aware of them at all\n",
        "\n",
        "* The User Interface: This exposes the underlying engine to the user, taking commands and presenting results\n",
        "\n",
        "###### Main job of the engine is to \n",
        "* Allow the user to search a database with keywords.\n",
        "  * user types search query -> extract important terms -> augment terms -> query()\n",
        "* Allow the user to insert new facts into the database using NL utterances.\n",
        "  * user types NL facts -> extract facts -> looks good to the user? -> commit if good cancel if bad and retry\n",
        "* Optionally, allow the user to manually check how GPT-3 interpreted the NL utterances, and either commit or cancel the data insertion.\n",
        "\n",
        "\n",
        "##### Proper practices to follow when building the engine\n",
        "* Facts are stored in a CSV file and are manipulated by the application as a Pandas dataframe. This is merely to keep things simple of course — in a production version, a database engine could be better (SQLite might be a good choice).\n",
        "* The engine contains methods to support a workflow that allows the user to examine the fact extraction before accepting it (BraindumpEngine class).\n",
        "* A preprocessor provides the mechanisms to build prompts for GPT-3 (BraindumpPreprocessor class).\n",
        "A postprocessor provides the mechanisms to interpret GPT-3’s outputs (BraindumpPostoprocessor class).\n",
        "* Unit tests should be in place, particularly to check the quality of the information extraction.\n",
        "\n",
        "\n",
        "#### The preprocessor\n",
        "* Transforms the user utterances into appropriate prompts\n",
        "* Inserting a user NL utterance (e.g., the facts we are allowing the users to type).\n",
        "* Inserting dynamic user choices (e.g., specific categories chosen by the user).\n",
        "* Inserting table or document schemas of specific files into the prompt text, so that the prompt can leverage them.\n",
        "\n",
        "#### The postprocessor\n",
        "*  is responsible for parsing GPT-3’s response and performing any necessary additional computation\n",
        "\n",
        "* Breaking lines, trimming text, and normalizing capitalization, among other simple text transformations.\n",
        "* Instantiating appropriate data structures that can be more easily manipulated later by the system.\n",
        "Checking for invalid elements (e.g., an invalid category).\n",
        "* Checking for offensive or illegal content. Remember that LLMs have been trained with vast amounts of rather arbitrary Internet content, which means they also carry information that users can find objectionable. Some platforms (such as the Azure OpenAI Service offering) already support filtering those at the API call level.\n",
        "* If a program is being generated (e.g., as can be easily done with the Codex version of GPT-3), applying appropriate program repair transformations as needed.\n",
        "* Checking for dangerous outputs. For example, if you are generating programs, it might be a good idea to ensure they cannot harm a user’s computer.\n",
        "\n",
        "#### Testing\n",
        "* Just as with any other software, LLM-based tools should also have automated tests. In addition to the general software engineering aspects regarding testing, we can add the following specific considerations:\n",
        "\n",
        "* The underlying model is expected to evolve over time. Though this typically means that the model gets better, it might also mean that prompts that worked well before stop working as well. Hence, it’s important to include tests to also guard against this expected behavioral change. In fact, as I write these lines, I’m wondering and fearing what the rumored upcoming GPT-4 model will do to my tutorial!\n",
        "* Different model outputs might be equally suitable as ground truth. In Braindump, for instance, it matters little if the model writes “buy” instead of “purchase” regarding a shopping list item. Hence, special matching operators can be used when writing tests, to make tests more resilient to such innocuous perturbations.\n",
        "\n"
      ],
      "metadata": {
        "id": "fEfcWGod2vNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question: \n",
        "* Question: So how can we be sure that the result really is what the user asked? And what do we do when the result fails, as it eventually most certainly will?\n",
        "* Answer: For each output, make sure it is easy for the user to inspect it, and that there’s a way to undo it and try again if the user finds it necessary.\n"
      ],
      "metadata": {
        "id": "xObYhoRp3e1v"
      }
    }
  ]
}